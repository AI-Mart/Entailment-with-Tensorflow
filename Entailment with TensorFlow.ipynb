{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import urllib\n",
    "import sys\n",
    "import os\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glove_zip_file = \"glove.6B.zip\"\n",
    "glove_vectors_file = \"glove.6B.50d.txt\"\n",
    "\n",
    "snli_zip_file = \"snli_1.0.zip\"\n",
    "snli_dev_file = \"snli_1.0_dev.txt\"\n",
    "snli_full_dataset_file = \"snli_1.0_train.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if sys.version[0] == \"3\": from urllib.request import urlretrieve\n",
    "else: from urllib import urlretrieve\n",
    "    \n",
    "#large file - 862 MB\n",
    "if (not os.path.isfile(glove_zip_file) and\n",
    "    not os.path.isfile(glove_vectors_file)):\n",
    "    urlretrieve (\"http://www-nlp.stanford.edu/data/glove.6B.zip\", \n",
    "                 glove_zip_file)\n",
    "\n",
    "#medium-sized file - 94.6 MB\n",
    "if (not os.path.isfile(snli_zip_file) and\n",
    "    not os.path.isfile(snli_dev_file)):\n",
    "    urlretrieve (\"http://www-nlp.stanford.edu/projects/snli/snli_1.0.zip\", \n",
    "                 snli_zip_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def unzip_single_file(zip_file_name, output_file_name):\n",
    "    \"\"\"\n",
    "        If the outFile is already created, don't recreate\n",
    "        If the outFile does not exist, create it from the zipFile\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(output_file_name):\n",
    "        with open(output_file_name, 'wb') as out_file:\n",
    "            with zipfile.ZipFile(zip_file_name) as zipped:\n",
    "                for info in zipped.infolist():\n",
    "                    if output_file_name in info.filename:\n",
    "                        with zipped.open(info) as requested_file:\n",
    "                            out_file.write(requested_file.read())\n",
    "                            return\n",
    "\n",
    "unzip_single_file(glove_zip_file, glove_vectors_file)\n",
    "unzip_single_file(snli_zip_file, snli_dev_file)\n",
    "# unzip_single_file(snli_zip_file, snli_full_dataset_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "glove_wordmap = {}\n",
    "with open(glove_vectors_file, \"r\") as glove:\n",
    "    for line in glove:\n",
    "        name, vector = tuple(line.split(\" \", 1))\n",
    "        glove_wordmap[name] = np.fromstring(vector, sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentence2sequence(sentence):\n",
    "    \"\"\"\n",
    "     \n",
    "    - Turns an input sentence into an (n,d) matrix, \n",
    "        where n is the number of tokens in the sentence\n",
    "        and d is the number of dimensions each word vector has.\n",
    "    \n",
    "      Tensorflow doesn't need to be used here, as simply\n",
    "      turning the sentence into a sequence based off our \n",
    "      mapping does not need the computational power that\n",
    "      Tensorflow provides. Normal Python suffices for this task.\n",
    "    \"\"\"\n",
    "    tokens = sentence.lower().split(\" \")\n",
    "    rows = []\n",
    "    words = []\n",
    "    #Greedy search for tokens\n",
    "    for token in tokens:\n",
    "        i = len(token)\n",
    "        while len(token) > 0 and i > 0:\n",
    "            word = token[:i]\n",
    "            if word in glove_wordmap:\n",
    "                rows.append(glove_wordmap[word])\n",
    "                words.append(word)\n",
    "                token = token[i:]\n",
    "                i = len(token)\n",
    "            else:\n",
    "                i = i-1\n",
    "    return rows, words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD8CAYAAAB9y7/cAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrKIc4M3MKur/A+U6u5AwxajOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109f418d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHwpJREFUeJzt3XuYZVV95vHvW9XVdes73TS3xgYiaoty64dwNYSRiMRH\nGIPxRpSMT3oMXjPKxFzmkUziM3GYcXi8JKaNKBGMGoyXgJFBkAFRLt3YYHNTlEYakKa6m6avdTn1\nmz/Obq2utYo+VbW7zqld7+d59lP7rLPW3mvts+tXq9beZ21FBGZmVl1tza6AmZkdWA70ZmYV50Bv\nZlZxDvRmZhXnQG9mVnEO9GZmFVf5QC/pPEmPSHpU0oebXZ+JknSVpE2S1o9IWyTpJkk/LX4ubGYd\nx0vSMknfk/SgpAckvb9In7btktQl6W5J9xVt+qsifdq2aSRJ7ZJ+JOn64nUl2lV1lQ70ktqBTwOv\nBVYAb5G0orm1mrAvAOeNSvswcHNEvBi4uXg9nQwBH4yIFcCpwLuLz2c6t6sfOCcijgdOAM6TdCrT\nu00jvR94aMTrqrSr0iod6IFTgEcj4ucRMQB8GbigyXWakIi4DdgyKvkC4Opi/Wrgwimt1CRFxNMR\ncW+xvp16ADmcadyuqNtRvOwolmAat2kvSUcAvwv844jkad+umaDqgf5w4IkRrzcWaVWxNCKeLtZ/\nCSxtZmUmQ9Jy4ETgLqZ5u4rhjXXAJuCmiJj2bSpcCfxXYHhEWhXaVXlVD/QzRtTnspiW81lImgN8\nDfhARDw/8r3p2K6IqEXECcARwCmSjhv1/rRrk6TXAZsiYu1YeaZju2aKqgf6J4FlI14fUaRVxTOS\nDgUofm5qcn3GTVIH9SB/bUT8a5E87dsFEBHPAd+jfm1lurfpDOD1kjZQHwI9R9I1TP92zQhVD/T3\nAC+WdJSk2cCbgW81uU5l+hbwjmL9HcA3m1iXcZMk4HPAQxHx8RFvTdt2SVoiaUGx3g2cCzzMNG4T\nQET8WUQcERHLqf8e3RIRFzPN2zVTqOqzV0o6n/rYYjtwVUR8tMlVmhBJ/wycDSwGngE+AnwD+Cpw\nJPA48PsRMfqCbcuSdCZwO/Bjfj3u++fUx+mnZbskvZL6Rcl26h2pr0bEf5d0ENO0TaNJOhv4UES8\nrkrtqrLKB3ozs5mu6kM3ZmYzngO9mVnFOdCbmVWcA72ZWcU50JuZtaDRE8hNxowI9JJWNbsOB0IV\n21XFNoHbZRMyegK5CZsRgR6o6slYxXZVsU3gdtk4jDGB3ITNlEBvZjad5CaQm7BZZWykVc3q7o2O\n+YvomLeQ7kOWBYDG+H5Y20D6xnCHkrQY409j21AuLb+z4fZ0u7k/uW39+fK17nr5jrkL6VlatGsc\n+691pvvPHZcxv0qXqb4yp2N7f/4crXVmGltsc3bvQnqXLPvVrlXL1Cu3/+ye8m1o37IzTZzTnS0/\n1J3WtW0w3Wq05WvwsiOeBeDIw2ex8viuAHho45Js3rZaY9uN9mzx/OeVO1aZY1rfVyZvZqMjP+vZ\nPQuYs6j+eWU/l9x5NcbvkDLtz/0OjrXdbEgc48QYfW7u2fMcA4M7xzqNGvKa3+6NzVvGOLijrL2/\n/wFgz4ik1RGxGvadQK74FvKkVTrQd8xfxNFv/y/7pLX35/POeyKNlDsOSX+j9gbZ0Tq3pmded1/+\nQ++fn57pueA79xcD2fJbVnQmaV1b0rO8a3N+/88vTz/23HHJ/eICROasmbUrTZv/893Z8tuOToPq\ncEd+X53Pp+0a6korlvtDC/mgMu9Ld6b7X3litvyWl3Ylab3PpMd1sCcfvX74vz6TpJ32oXdl83Zu\na2y7A3Pz+8p9XrnzqnNb/g9w9rhmTqGOnWP8AZ+dlp+1J/29GKv+XVvTnW0/PB+ictvNpWU7VcC8\nDXv2eX3PvZ/O5huPvi017rrxiIbydhz6sz0RsXKMt/dOIHc+0AXMk3RNMbfQhHjoxsysFEEthhta\nXnArY08gN2GV7tGbmU2VAIZbdDp+B3ozs5IMl3Pt9Fci4lbg1slux4HezKwEQTC4n2GZZnGgNzMr\nQQA1D92YmVWbx+jNzCosgFqLPsjJgd7MrCStOULf5PvoJS2QdGmxfnYZs7SZmTVDENQaXKZas78w\ntQC4tMl1MDObtAgYbHCZas0euvlb4BhJ64BBYKek64DjgLXAxRERkk4GPg7MAfqASyLi6WZV2sws\nJWpjzrrUXM3u0X8Y+FlEnABcBpwIfABYARwNnCGpA/gkcFFEnAxcBXx0rA1KWiVpjaQ1td2ZyavM\nzA6AAIajsWWqNbtHP9rdEbERoOjlLweeo97Dv0kSQDswZm++mAFuNfCrGSvNzKZCq/boWy3Qj5xD\nsUa9fgIeiIjTmlMlM7P9q39hqjUDfbOHbrYDc/eT5xFgiaTTACR1SHr5Aa+Zmdk4BDAYbQ0tU62p\nPfqI2CzpDknrgd3AM5k8A5IuAj4haT71Ol8JPDC1tTUzG1sgak3vO+c1fegmIt46Rvp7RqyvA141\nZZUyM5uA4bGe1tNkTQ/0ZmZV0Mpj9A70ZmalELUmjL83woHezKwE9SdMOdCbmVVWhBiI9mZXI8uB\n3sysJMMeozczq676xVgP3ZiZVZgvxjZF+wDMfWJ4VFp++hvV0rSeZ9PHCPQdn/8g52xs/JEDg73p\nv3dznxxK0jad3Jktf/Da/iRt29Gzk7SeTfm2DvWk++9fkObrfC5ffs+itPzs59N8W4/tzpY/aP2O\nNHGMJ/M8dmH6xemuzen+Z+3Ml9/2kjR94drfSNLaN2XqBGz5g3TMdUsm34u+nt//lVuXJ2lDnfl/\n77ecmv46zt2Q5hvuyBanfSBNaxtK67X1Zfn9L3w4zbvo3rS1O4/OnCzAYG/6uzHQke5r95L8/gfm\npe2fvW2MczhzarWnvxbsOjS/r02v2ndf/Y9PfsjFF2PNzGaAmr8wZWZWXYEYjNYMqa1ZKzOzacYX\nY83MKi6Qh27MzKrOF2PNzCosAt9eaWZWZfWLseVMgSCpC7gN6KQep6+LiI9MdHsO9GZmJSnxYmw/\ncE5E7JDUAXxf0r9HxJ0T2ZgDvZlZCQKV9uCRiAhg77f4Oool/+2xBrTmgJKZ2TRUo62hpRGS2iWt\nAzYBN0XEXROtV8sEekkXSlox4vUlkg5rZp3MzBoVwHC0NbQAiyWtGbGsSrYXUYuIE4AjgFMkHTfR\nuk3p0I2k9ojIzCoDwIXA9cCDxetLgPXAU1NQNTOzSdJ4HiXYFxErG8kYEc9J+h5wHvWYOG6l9egl\nLZf0sKRrJT0k6TpJPZI2SPqYpHuBN0o6RtJ3JK2VdLukl0o6HXg9cIWkdZL+FFgJXFu8/l1J3xix\nr3Mlfb2supuZTVYAg9He0LI/kpZIWlCsdwPnAg9PtG5l9+hfArwzIu6QdBVwaZG+OSJOApB0M/Cu\niPippN8E/i4izpH0LeD6iLiuyPda4EMRsUaSgP8taUlEPAv8IXBVyXU3M5uwCO0dlinDocDVktqp\nd8i/GhHXT3RjZQf6JyLijmL9GuB9xfpXACTNAU4H/qUeu4H6faIvKCJC0heBiyV9HjgNeHsubzHW\ntQpgds/CCTbDzGz8yvrCVETcD5xYysYoP9CPvv1n7+udxc824LniAsN4fR74N2AP8C8RkU7gDkTE\namA1wJxFyyZ8O5KZ2XjU56Nvzbluyr7r5khJpxXrbwW+P/LNiHgeeEzSGwFUd3zx9nZg5FMm9nkd\nEU9RvzD7l9SDvplZC6k/YaqRZaqVvcdHgHdLeghYCPx9Js/bgHdKug94ALigSP8ycJmkH0k6BvgC\n8JniYuze58lcS3146KGS621mNin12yvV0DLVyh66GYqIi0elLR/5IiIeo36bEKPS7wBWjEj6GfC1\nUdnOBD47+WqamZWrzLluyjZtpkCQtJb6WP8Hm10XM7Ocyk9THBEbgAl/c6uB7Z98oLZtZjZZ9WmK\nW/Ni7LTp0ZuZtbpmjL83woHezKwE9dkrKz50Y2Y2k9WnQHCgNzOrMPfozcwqr1W/GVvpQD/UDZtf\nse+B7zpuWzbvvH+al6TVZqcfWv+ygWz553anU/YcdvuubN4Fu9J7bQfnpWlznxjOlq91pXmVmexh\nw1vzM0Ac+dXBJO2ZUzqStLZ8U1n4k3Sm6cGexnsybb94Jknb9LpjsnmPuCWtxOPnp3U96t/6s+VV\n60rSnj734CRtON1k3VA600b3E+mvTffGrdniVz96apI2uDQfDHqfTD+vWXvStOGhfPndS9L0hY+m\n9R/qzf/ad21O8245aVGSNtiT3//sHWldO7el58q8DfmZyp9+b/oZzv98bzbvUHdahwU/eCJJ6zrh\n8Gz5Q364b1u3bp78bCm+68bMbAbw0I2ZWYWV+czYsjnQm5mVIIAh9+jNzKrNQzdmZlXWpJkpG+FA\nb2ZWglZ+8IgDvZlZSdyjNzOrsL0PHmlFDvRmZiUIxNCwL8aamVVaq47RT+jPj6T3SXpI0pOSPlV2\npczMpp2o3jNjLwVeXSwry6tOnqRZEZFOxGFm1iJaeYx+3D16SZ8Bjgb+HVg4In25pFsk3S/pZklH\nSmqX9JjqFkiqSXpVkf82SS+W1CvpKkl3S/qRpAuK9y+R9C1JtwA3Szq0KLNO0npJZ5VzCMzMytGq\nPfpxB/qIeBfwFPDbwMgp+z4JXB0RrwSuBT4RETXgEWAFcCZwL3CWpE5gWUT8FPgL4JaIOKXY5hWS\n9k5ZdxJwUUT8FvBW4MaIOAE4Hlg37taamR0ggagNtzW0TLUyL8aeBryhWP8i8D+L9duBVwFHAf8D\n+CPg/wH3FO//DvB6SR8qXncBRxbrN0XElmL9HuAqSR3ANyIiG+glrQJWAcyavzCXxczsgKjUxdhx\nug04CzgF+DawADib+h8AAAG/FxEnFMuREfFQ8d7OvRuJiNuo/8F4EviCpLfndhYRqyNiZUSsbO/N\nz2VtZla2aOGLsWUG+h8Aby7W38avA/ndwOnAcETsoT7k8p+p/wEAuBF4ryQBSDoxt3FJLwKeiYjP\nAv9IfVjHzKxlRKihZX8kLZP0PUkPSnpA0vsnU68yh27eC3xe0mXAs8AfAkREv6QngDuLfLcDbwF+\nXLz+a+BK4H5JbcBjwOsy2z8buEzSILADyPbozcyao9Te+hDwwYi4V9JcYK2kmyLiwYlsbEKBPiKW\nF6tfKBYi4nHgnDHynzVi/UvAl0a83k29hz+6zK+2Xby+Grh6IvU1M5sKjfTWG9tOPA08Xaxvl/QQ\ncDgwdYHezMz2FQG14fLH3yUtB04E7proNhzozcxKMo67bhZLWjPi9eqIWD06k6Q5wNeAD0TE8xOt\nlwO9mVkJgnEN3fRFxAvOKlDcSv414NqI+NfJ1M2B3sysFOVdjC3uQvwc8FBEfHyy22vNOTXNzKah\niMaWBpwB/AFwTjHtyzpJ50+0Xu7Rm5mVpMS7br4P5X3N1oHezKwE9btuWnOQxIHezKwkDQ7LTLlK\nB/pZu2HxfcP7pO3oy090tnth+gnN6k/T5t3XmS1/2C1bkrRNp+X31flcut3hzCex7Zh876BjR5re\n3p/mO/yb+Y9383HtSdri+2tJ2tZj03wAXdvStP6F6X+Zh/xge7Z8/8uXZbY5nMkJT/zO7CRt1s50\nXxrIl9+9NM3b88v0+Ee+qVnzH0v3tfnEBdm8PdekeZ85NV/XWlf6uS69Mz3YfSfOz5aftSdNi7a0\n/YNjTAHV3p/Wq2dTeqz2LMqfV7sOTus/a09afmBO/mB3fjf93dp5SDYrA/PTdvU+uSRJ23FIvq6L\ntgzsm1BSgC5r6KZslQ70ZmZTJWhsHptmcKA3MytJi47cONCbmZUiIA7AFAhlcKA3MyuJh27MzCrO\nd92YmVXYOOe6mVIO9GZmZQjAgd7MrNo8dGNmVmlq2btuDujEDJI2SFp8IPdhZtYyosFlirlHb2ZW\nhmjdi7Gl9egl9Uq6QdJ9ktZLelPx1nsl3Svpx5JeWuRdJOkbku6XdKekVxbpl0u6StKtkn4u6X0j\ntn+xpLuLeZn/QdI4ZicxM5sCLdqjL3Po5jzgqYg4PiKOA75TpPdFxEnA3wMfKtL+CvhRRLwS+HPg\nn0Zs56XAa4BTgI9I6pD0MuBNwBkRcQJQA95WYt3NzEqgBpepVWag/zFwrqSPSTorIvZOu7f3WYdr\ngeXF+pnAFwEi4hbgIEnzivduiIj+iOgDNgFLgf8AnAzcI2ld8froXCUkrZK0RtKawf4dJTbPzGw/\nhhtcplhpY/QR8RNJJwHnA38j6ebirb0T6NYa3N/ICXf3lhFwdUT8WQP1WA2sBpizaFmL3uxkZpXT\nwvfRlzlGfxiwKyKuAa4ATnqB7LdTDL1IOpv68M7zL5D/ZuAiSQcXZRZJelEpFTczK0mJz4wtVZl3\n3bwCuELSMDAI/DFw3Rh5LweuknQ/sAt4xwttOCIelPSXwP+V1FZs/93A4yXV3cxs8lp0DKHMoZsb\ngRtHJS8f8f4a4OxifQtwYWYbl496fdyI9a8AXymrvmZmpWvRoRvfR29mVhJVvUdvZjajhaBFp0Bw\noDczK4t79GZmFedAb2ZWcQ70ZmYV1sJfmHKgNzMrSavedXNA56M3M5tRSpq9spjFd5Ok9WVUq9I9\n+tps2HHEvrMZayifd+7GwSTt+eUdSVrHjvyn9MwZC5O0eRvyO9t1cHrYcz2Bgx6sZcvvXpT+fV70\n4O4kbc/BndnyB6/tT9I2nZTm7Xo239bhWem/p+170rxte9JjCrDpt+am20wPNQALH0y3O5AWZ/Mr\nerLlD3ow/Qx6rr83Sdv+hpX5/a9LZ8MezkyQPTzGb9K3/8+VSdpr/vRPsnmHZ6Vt7T84bdfg3Pzw\nwOznM+XnpudK+0C2OH2vTM+B3Oc6d2P+vOzoSeuVO1e7t+Rn9ZrzdJq+9cX5A9vzy8x5sXB2kqYx\nJhAbnTcy5/RElNij/wLwKfad2XfCKh3ozcymVElj9BFxm6TlpWwMB3ozs3I06aEijXCgNzMrS+OB\nfrGkNSNery6mWD8gHOjNzEoy1jWBjL6IyF8YOgAc6M3MytKiQze+vdLMrASKxpf9bkv6Z+CHwEsk\nbZT0zsnUzT16M7OylHfXzVtK2VDBgd7MrCwtOnTjQG9mVpJWnQLBgd7MrAwxrrtuplRLX4yV9INm\n18HMrGElzXVTtpbu0UfE6c2ug5lZw1p06KbVe/Q7ip9nS7pV0nWSHpZ0raTWnPjZzGassm6vLFtL\nB/pRTgQ+AKwAjgbOyGWStErSGklrart2TmX9zMxa0nQK9HdHxMaIGAbWActzmSJidUSsjIiV7T29\nU1pBM5vhPEY/aSMnUa8xvepuZlXXwnfdOFiamZWlRS/GOtCbmZVA+AtTExIRc4qftwK3jkh/T5Oq\nZGY2Ngd6M7MKa9Ktk41woDczK4svxpqZVZt79GZmVedAb2ZWYU36MlQjHOjNzErioRszs6pzoG+O\n4fZ9X7cP5fPVutNpf3KPfxyam580s3Nr+glHez5v21Cat9aZ5p39XL6yOw7rTNK2L+9K0ro217Ll\ntx47O5M3U/8x5gftn5++0ZGZP642N60TQM8v030Nd+T31bErvY1Bw+n+28b4XAd7Mp/rUJq555n+\nJA1gz8K0DZ3b0+M6WMtPGzW/rTtJG6vX19OX1qt/fnuS1rEjv4HR5zrkz6veJ/O3hgx1ZY5r5hQa\n6s6fGO39ab1m7UnT+uflj1XX1nRns8aYlzB3vuSO1VjnRcf2fd9QrZwI7SkQzMyqzGP0ZmbVpmJp\nRQ70ZmZlcY/ezKzafNeNmVnVOdCbmVWYHzxiZjYDuEdvZlZtrTpGP50eDm5m1tpKfDi4pPMkPSLp\nUUkfnky1HOjNzEqiaGzZ73akduDTwGuBFcBbJK2YaL2aGuglLZB0abF+tqTrm1kfM7MJC+oPHmlk\n2b9TgEcj4ucRMQB8GbhgolVrdo9+AXBpk+tgZjZpex8OXkaPHjgceGLE641F2oQ0+2Ls3wLHSFoH\nDAI7JV0HHAesBS6OiJB0MvBxYA7QB1wSEU83q9JmZlmNX4xdLGnNiNerI2J1+RWqa3ag/zBwXESc\nIOls4JvAy4GngDuAMyTdBXwSuCAinpX0JuCjwH/KbVDSKmAVQMe8hQe+BWZmBUXDkb4vIla+wPtP\nAstGvD6iSJuQZgf60e6OiI0ARS9/OfAc9R7+TZIA2oExe/PFX8XVAN2HLGvRm53MrHLKnb3yHuDF\nko6iHuDfDLx1ohtrtUA/clLwGvX6CXggIk5rTpXMzBpT1n30ETEk6T3AjdQ7t1dFxAMT3V6zA/12\nYO5+8jwCLJF0WkT8UFIHcOxkGm1mdiCUOQVCRHwb+HYZ22pqoI+IzZLukLQe2A08k8kzIOki4BOS\n5lOv85WAA72ZtZYWHSxudo+eiMiOO0XEe0asrwNeNWWVMjMbr8ZvnZxyTQ/0ZmaV4UBvZlZde78w\n1Yoc6M3MSqLh1oz0DvRmZmUo9z76UjnQm5mVxE+YMjOrOvfozcyqzRdjmyDaYWD+vkd+cF7+k+hf\nmB6KJfcNJWmDPfmZnbufHUzSNq3szObtfTKtw+4lStL6zsoWZ/6P0rRQWv7xC9I0gPkPpOnzNqT1\n3/jq9mz5xZn9d22pJWlD3WOUvz2dm+np1+ZnYN15cLqN7Uen/x8f+7nN2fKPvXFJkrbrT05P0iJ/\nqNj+kvS4bMnkm/9A/rz4jVsvSdJ6D87nzf3bv+DmnyVpu1Yuz5bffmR6Drf3p+fankX5/Q/1pGlz\nn0grtePw/Oc6a1e6r9k70/K12dni7F6UbrfWnc/bf1D6gR31xfS86ntV/rzqP6hjn9fDs8Y4AcYj\ngMYnNZtSlQ70ZmZTyWP0ZmYV5vvozcyqLsJDN2ZmVecevZlZ1TnQm5lVm3v0ZmZVFkCtNSO9A72Z\nWUncozczqzrfdWNmVm2t2qPPfxf6AJC0o/h5mKTrGs2fSb9Q0oqy62dmNikxjmWKTVmg3ysinoqI\niyaxiQsBB3ozaykCVIuGlqm230AvqVfSDZLuk7Re0pskbZC0uHh/paRbi/XLJV0l6VZJP5f0vsz2\nlktaX6z3SPqqpAclfV3SXZJWjsj70WK/d0paKul04PXAFZLWSTqmpONgZjZpimhomWqN9OjPA56K\niOMj4jjgO/vJ/1LgNcApwEckdbxA3kuBrRGxAvhvwMkj3usF7oyI44HbgD+KiB8A3wIui4gTIiKd\n2s/MrBmm+dDNj4FzJX1M0lkRsW0/+W+IiP6I6AM2AUtfIO+ZwJcBImI9cP+I9waA64v1tcDyBuqK\npFWS1khaU9u5s5EiZmYliF/Pd7O/ZYrt966biPiJpJOA84G/kXQzMMSv/0h0jSrSP2K91sg+xjAY\n8asj0vB2ImI1sBqg6/BlLXoN3MyqaNredSPpMGBXRFwDXAGcBGzg18MsvzeJ/d8B/H6xnxXAKxoo\nsx2YO4l9mpkdGNO1R089+F4haRgYBP4Y6AY+J+mvgVsnsf+/A66W9CDwMPAAsL+hoS8Dny0u9F7k\ncXozawlBU+6oaUQjQzc3Ajdm3jo2k/fyUa+PG7E+p/i5Adibvge4OCL2FHfQfBd4fGT+Yv064Lpi\n/Q58e6WZtaIpiPOS3ghcDrwMOCUi1uyvTLO/GdsDfK+4M0fApREx0OQ6mZlNyBTdOrkeeAPwD40W\naGqgj4jtwMr9ZjQzmw6mINBHxEMAUuMPNG92j97MrBoC8MPBzcyqS4zrW6+LJY0cW19d3Bpe35b0\nXeCQTLm/iIhvjrduDvRmZmUZbrhL3xcRYw5bR8Sry6lQnQO9mVkZWnjoZspnrzQzq6qpmNRM0n+U\ntBE4DbhBUu729324R29mVpapuevm68DXx1Om0oG+bRB6n9o3rdaX/yemuy/9n2v74enhGZ6d39eu\nQzqTtEUPDWXz1mant0Utejg9QeY/lp/4c9fiNG2wN01bNuY8o2m9Np2U7qv3F/nSkZnQY+fS9FjN\n+0X+KxFbf/OwzDbzt4q1DaX76no2/Qw3nZ45KEDvU2n5pTc8lqQ9d+aLsuU7t6btGpif1rX72fz/\n7Nef+akk7cKbL8vmjcypufPUo5K0HYe1Z8vP2pWm9S9I69o+kA9Gtc4072Bvmjb7+Xz5yFRr58Fp\n4qw92eJoON1ue3/+vOjqS/NuO/nQJK02xty5O5fuW6/hjsZvVRxbc6Y3aESlA72Z2ZQJYLpOgWBm\nZo1pxkNFGuFAb2ZWFgd6M7MKCyBznaEVONCbmZXCF2PNzKrPgd7MrMICqLXmV2Md6M3MShEQDvRm\nZtXmoRszswrzXTdmZjOAe/RmZhXnQG9mVmERUKs1uxZZlQv0klYBqwA65ixscm3MbEZp0R595R48\nEhGrI2JlRKyc1Z2Zu9fM7ECJaGyZYpXr0ZuZNUe07F0307JHL+nbktKnV5iZNUtAxHBDy1Sblj36\niDi/2XUwM0t4CgQzswqLgGEHejOzamvRu24c6M3MShLu0ZuZVZkfPGJmVm2e1MzMrNoCCE+BYGZW\nYeEHj5iZVV606NCNokUvHpRB0rPA48BioK/J1TkQqtiuKrYJ3K5W96KIWDKZDUj6DvXj0Yi+iDhv\nMvsbj0oH+r0krYmIlc2uR9mq2K4qtgncLmuuaTnXjZmZNc6B3sys4mZKoF/d7AocIFVsVxXbBG6X\nNdGMGKM3M5vJZkqP3sxsxnKgNzOrOAd6M7OKc6A3M6s4B3ozs4r7/+hDIZUeES7jAAAAAElFTkSu\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11fcf9898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize(sentence):\n",
    "    rows, words = sentence2sequence(sentence)\n",
    "    mat = np.vstack(rows)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    shown = ax.matshow(mat, aspect=\"auto\")\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    fig.colorbar(shown)\n",
    "    \n",
    "    ax.set_yticklabels([\"\"]+words)\n",
    "    plt.show()\n",
    "    \n",
    "visualize(\"The quick brown fox jumped over the lazy dog.\")\n",
    "visualize(\"The pretty flowers shone in the sunlight.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rnn_size = 64\n",
    "rnn = tf.contrib.rnn.BasicRNNCell(rnn_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Constants setup\n",
    "max_hypothesis_length, max_evidence_length = 30, 30\n",
    "batch_size, vector_size, hidden_size = 128, 50, 64\n",
    "\n",
    "lstm_size = hidden_size\n",
    "\n",
    "weight_decay = 0.0001\n",
    "\n",
    "learning_rate = 1\n",
    "\n",
    "input_p, output_p = 0.5, 0.5\n",
    "\n",
    "training_iterations_count = 100000\n",
    "\n",
    "display_step = 10\n",
    "\n",
    "def score_setup(row):\n",
    "    convert_dict = {\n",
    "      'entailment': 0,\n",
    "      'neutral': 1,\n",
    "      'contradiction': 2\n",
    "    }\n",
    "    score = np.zeros((3,))\n",
    "    for x in range(1,6):\n",
    "        tag = row[\"label\"+str(x)]\n",
    "        if tag in convert_dict: score[convert_dict[tag]] += 1\n",
    "    return score / (1.0*np.sum(score))\n",
    "\n",
    "def fit_to_size(matrix, shape):\n",
    "    res = np.zeros(shape)\n",
    "    slices = [slice(0,min(dim,shape[e])) for e, dim in enumerate(matrix.shape)]\n",
    "    res[slices] = matrix[slices]\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data_into_scores():\n",
    "    import csv\n",
    "    with open(\"snli_1.0_dev.txt\",\"r\") as data:\n",
    "        train = csv.DictReader(data, delimiter='\\t')\n",
    "        evi_sentences = []\n",
    "        hyp_sentences = []\n",
    "        labels = []\n",
    "        scores = []\n",
    "        for row in train:\n",
    "            hyp_sentences.append(np.vstack(\n",
    "                    sentence2sequence(row[\"sentence1\"].lower())[0]))\n",
    "            evi_sentences.append(np.vstack(\n",
    "                    sentence2sequence(row[\"sentence2\"].lower())[0]))\n",
    "            labels.append(row[\"gold_label\"])\n",
    "            scores.append(score_setup(row))\n",
    "        \n",
    "        hyp_sentences = np.stack([fit_to_size(x, (max_hypothesis_length, vector_size))\n",
    "                          for x in hyp_sentences])\n",
    "        evi_sentences = np.stack([fit_to_size(x, (max_evidence_length, vector_size))\n",
    "                          for x in evi_sentences])\n",
    "                                 \n",
    "        return (hyp_sentences, evi_sentences), labels, np.array(scores)\n",
    "    \n",
    "data_feature_list, correct_values, correct_scores = split_data_into_scores()\n",
    "\n",
    "l_h, l_e = max_hypothesis_length, max_evidence_length\n",
    "N, D, H = batch_size, vector_size, hidden_size\n",
    "l_seq = l_h + l_e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lstm_drop =  tf.contrib.rnn.DropoutWrapper(lstm, input_p, output_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# N: The number of elements in each of our batches, \n",
    "#   which we use to train subsets of data for efficiency's sake.\n",
    "# l_h: The maximum length of a hypothesis, or the second sentence.  This is\n",
    "#   used because training an RNN is extraordinarily difficult without \n",
    "#   rolling it out to a fixed length.\n",
    "# l_e: The maximum length of evidence, the first sentence.  This is used\n",
    "#   because training an RNN is extraordinarily difficult without \n",
    "#   rolling it out to a fixed length.\n",
    "# D: The size of our used GloVe or other vectors.\n",
    "hyp = tf.placeholder(tf.float32, [N, l_h, D], 'hypothesis')\n",
    "evi = tf.placeholder(tf.float32, [N, l_e, D], 'evidence')\n",
    "y = tf.placeholder(tf.float32, [N, 3], 'label')\n",
    "# hyp: Where the hypotheses will be stored during training.\n",
    "# evi: Where the evidences will be stored during training.\n",
    "# y: Where correct scores will be stored during training.\n",
    "\n",
    "# lstm_size: the size of the gates in the LSTM, \n",
    "#    as in the first LSTM layer's initialization.\n",
    "lstm_back = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "# lstm_back:  The LSTM used for looking backwards \n",
    "#   through the sentences, similar to lstm.\n",
    "\n",
    "# input_p: the probability that inputs to the LSTM will be retained at each\n",
    "#   iteration of dropout.\n",
    "# output_p: the probability that outputs from the LSTM will be retained at \n",
    "#   each iteration of dropout.\n",
    "lstm_drop_back = tf.contrib.rnn.DropoutWrapper(lstm_back, input_p, output_p)\n",
    "# lstm_drop_back:  A dropout wrapper for lstm_back, like lstm_drop.\n",
    "\n",
    "\n",
    "fc_initializer = tf.random_normal_initializer(stddev=0.1) \n",
    "# fc_initializer: initial values for the fully connected layer's weights.\n",
    "# hidden_size: the size of the outputs from each lstm layer.  \n",
    "#   Multiplied by 2 to account for the two LSTMs.\n",
    "fc_weight = tf.get_variable('fc_weight', [2*hidden_size, 3], \n",
    "                            initializer = fc_initializer)\n",
    "# fc_weight: Storage for the fully connected layer's weights.\n",
    "fc_bias = tf.get_variable('bias', [3])\n",
    "# fc_bias: Storage for the fully connected layer's bias.\n",
    "\n",
    "# tf.GraphKeys.REGULARIZATION_LOSSES:  A key to a collection in the graph\n",
    "#   designated for losses due to regularization.\n",
    "#   In this case, this portion of loss is regularization on the weights\n",
    "#   for the fully connected layer.\n",
    "tf.add_to_collection(tf.GraphKeys.REGULARIZATION_LOSSES, \n",
    "                     tf.nn.l2_loss(fc_weight)) \n",
    "\n",
    "x = tf.concat([hyp, evi], 1) # N, (Lh+Le), d\n",
    "# Permuting batch_size and n_steps\n",
    "x = tf.transpose(x, [1, 0, 2]) # (Le+Lh), N, d\n",
    "# Reshaping to (n_steps*batch_size, n_input)\n",
    "x = tf.reshape(x, [-1, vector_size]) # (Le+Lh)*N, d\n",
    "# Split to get a list of 'n_steps' tensors of shape (batch_size, n_input)\n",
    "x = tf.split(x, l_seq,)\n",
    "\n",
    "# x: the inputs to the bidirectional_rnn\n",
    "\n",
    "\n",
    "# tf.contrib.rnn.static_bidirectional_rnn: Runs the input through\n",
    "#   two recurrent networks, one that runs the inputs forward and one\n",
    "#   that runs the inputs in reversed order, combining the outputs.\n",
    "rnn_outputs, _, _ = tf.contrib.rnn.static_bidirectional_rnn(lstm, lstm_back,\n",
    "                                                            x, dtype=tf.float32)\n",
    "# rnn_outputs: the list of LSTM outputs, as a list. \n",
    "#   What we want is the latest output, rnn_outputs[-1]\n",
    "\n",
    "classification_scores = tf.matmul(rnn_outputs[-1], fc_weight) + fc_bias\n",
    "# The scores are relative certainties for how likely the output matches\n",
    "#   a certain entailment: \n",
    "#     0: Positive entailment\n",
    "#     1: Neutral entailment\n",
    "#     2: Negative entailment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('Accuracy'):\n",
    "    predicts = tf.cast(tf.argmax(classification_scores, 1), 'int32')\n",
    "    y_label = tf.cast(tf.argmax(y, 1), 'int32')\n",
    "    corrects = tf.equal(predicts, y_label)\n",
    "    num_corrects = tf.reduce_sum(tf.cast(corrects, tf.float32))\n",
    "    accuracy = tf.reduce_mean(tf.cast(corrects, tf.float32))\n",
    "\n",
    "with tf.variable_scope(\"loss\"):\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "        logits = classification_scores, labels = y)\n",
    "    loss = tf.reduce_mean(cross_entropy)\n",
    "    total_loss = loss + weight_decay * tf.add_n(\n",
    "        tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "\n",
    "opt_op = optimizer.minimize(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/782 [00:01<09:22,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0.0, Minibatch Loss= 1.118880, Training Accuracy= 0.41406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 13/782 [00:01<02:21,  5.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 10.0, Minibatch Loss= 1.088144, Training Accuracy= 0.40625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 23/782 [00:02<01:07, 11.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 20.0, Minibatch Loss= 1.093669, Training Accuracy= 0.36719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 33/782 [00:03<00:52, 14.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 30.0, Minibatch Loss= 1.098277, Training Accuracy= 0.36719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 43/782 [00:03<00:52, 14.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 40.0, Minibatch Loss= 1.087354, Training Accuracy= 0.39062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 53/782 [00:04<00:48, 14.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 50.0, Minibatch Loss= 1.075323, Training Accuracy= 0.46875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 63/782 [00:05<00:49, 14.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 60.0, Minibatch Loss= 1.087084, Training Accuracy= 0.35938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 73/782 [00:05<00:49, 14.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 70.0, Minibatch Loss= 1.094530, Training Accuracy= 0.40625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 83/782 [00:06<00:48, 14.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 80.0, Minibatch Loss= 1.080012, Training Accuracy= 0.41406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 91/782 [00:07<01:00, 11.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 90.0, Minibatch Loss= 1.080032, Training Accuracy= 0.39844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 103/782 [00:08<00:57, 11.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 100.0, Minibatch Loss= 1.185560, Training Accuracy= 0.40625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 113/782 [00:09<00:49, 13.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 110.0, Minibatch Loss= 1.067651, Training Accuracy= 0.50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 123/782 [00:09<00:45, 14.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 120.0, Minibatch Loss= 1.067986, Training Accuracy= 0.46094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 133/782 [00:10<00:46, 14.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 130.0, Minibatch Loss= 1.049839, Training Accuracy= 0.43750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 143/782 [00:11<00:45, 13.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 140.0, Minibatch Loss= 1.067825, Training Accuracy= 0.45312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 153/782 [00:11<00:43, 14.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 150.0, Minibatch Loss= 1.062599, Training Accuracy= 0.42969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 163/782 [00:12<00:43, 14.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 160.0, Minibatch Loss= 1.075096, Training Accuracy= 0.42969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 173/782 [00:13<00:41, 14.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 170.0, Minibatch Loss= 1.078179, Training Accuracy= 0.48438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 183/782 [00:13<00:42, 14.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 180.0, Minibatch Loss= 1.076858, Training Accuracy= 0.41406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 193/782 [00:14<00:40, 14.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 190.0, Minibatch Loss= 1.059287, Training Accuracy= 0.39062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 203/782 [00:15<00:38, 14.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 200.0, Minibatch Loss= 1.049474, Training Accuracy= 0.44531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 213/782 [00:15<00:37, 15.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 210.0, Minibatch Loss= 1.070277, Training Accuracy= 0.42969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 223/782 [00:16<00:37, 14.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 220.0, Minibatch Loss= 1.069427, Training Accuracy= 0.42969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 231/782 [00:17<00:44, 12.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 230.0, Minibatch Loss= 1.035334, Training Accuracy= 0.46094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 243/782 [00:18<00:44, 12.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 240.0, Minibatch Loss= 1.030936, Training Accuracy= 0.52344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 253/782 [00:19<00:39, 13.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 250.0, Minibatch Loss= 1.025337, Training Accuracy= 0.50781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 263/782 [00:19<00:36, 14.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 260.0, Minibatch Loss= 1.061574, Training Accuracy= 0.46094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 273/782 [00:20<00:34, 14.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 270.0, Minibatch Loss= 1.052368, Training Accuracy= 0.49219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 283/782 [00:21<00:33, 15.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 280.0, Minibatch Loss= 1.062466, Training Accuracy= 0.47656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 293/782 [00:21<00:32, 15.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 290.0, Minibatch Loss= 1.021823, Training Accuracy= 0.49219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 303/782 [00:22<00:33, 14.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 300.0, Minibatch Loss= 1.043971, Training Accuracy= 0.52344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 313/782 [00:23<00:31, 14.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 310.0, Minibatch Loss= 1.044896, Training Accuracy= 0.46875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 323/782 [00:23<00:30, 14.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 320.0, Minibatch Loss= 1.078340, Training Accuracy= 0.37500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 333/782 [00:24<00:32, 14.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 330.0, Minibatch Loss= 1.036380, Training Accuracy= 0.48438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 343/782 [00:25<00:30, 14.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 340.0, Minibatch Loss= 1.049838, Training Accuracy= 0.46094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 353/782 [00:25<00:28, 15.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 350.0, Minibatch Loss= 1.047664, Training Accuracy= 0.45312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 363/782 [00:26<00:27, 15.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 360.0, Minibatch Loss= 1.039294, Training Accuracy= 0.42969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 373/782 [00:27<00:26, 15.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 370.0, Minibatch Loss= 1.069536, Training Accuracy= 0.43750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 383/782 [00:27<00:25, 15.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 380.0, Minibatch Loss= 1.092009, Training Accuracy= 0.36719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 393/782 [00:28<00:24, 15.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 390.0, Minibatch Loss= 1.072459, Training Accuracy= 0.49219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 403/782 [00:29<00:24, 15.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 400.0, Minibatch Loss= 1.066622, Training Accuracy= 0.43750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 413/782 [00:29<00:23, 15.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 410.0, Minibatch Loss= 1.047420, Training Accuracy= 0.46875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 423/782 [00:30<00:23, 15.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 420.0, Minibatch Loss= 1.064384, Training Accuracy= 0.42969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 433/782 [00:30<00:22, 15.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 430.0, Minibatch Loss= 1.018015, Training Accuracy= 0.50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 443/782 [00:31<00:22, 14.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 440.0, Minibatch Loss= 1.051622, Training Accuracy= 0.46094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 453/782 [00:32<00:21, 14.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 450.0, Minibatch Loss= 1.022696, Training Accuracy= 0.56250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 463/782 [00:32<00:21, 15.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 460.0, Minibatch Loss= 1.018428, Training Accuracy= 0.52344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 473/782 [00:33<00:20, 15.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 470.0, Minibatch Loss= 1.004266, Training Accuracy= 0.55469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 483/782 [00:34<00:19, 15.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 480.0, Minibatch Loss= 1.031036, Training Accuracy= 0.49219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 493/782 [00:34<00:18, 15.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 490.0, Minibatch Loss= 1.080269, Training Accuracy= 0.43750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 503/782 [00:35<00:17, 15.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 500.0, Minibatch Loss= 1.065894, Training Accuracy= 0.46094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 513/782 [00:36<00:17, 15.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 510.0, Minibatch Loss= 1.063315, Training Accuracy= 0.47656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 523/782 [00:36<00:17, 15.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 520.0, Minibatch Loss= 1.054603, Training Accuracy= 0.46875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 533/782 [00:37<00:16, 15.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 530.0, Minibatch Loss= 1.049439, Training Accuracy= 0.50781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 543/782 [00:38<00:18, 12.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 540.0, Minibatch Loss= 1.079491, Training Accuracy= 0.39062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 552/782 [00:39<00:27,  8.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 550.0, Minibatch Loss= 1.057841, Training Accuracy= 0.42969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 564/782 [00:40<00:19, 11.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 560.0, Minibatch Loss= 1.064527, Training Accuracy= 0.48438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 572/782 [00:41<00:17, 12.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 570.0, Minibatch Loss= 1.017023, Training Accuracy= 0.55469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 584/782 [00:42<00:17, 11.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 580.0, Minibatch Loss= 1.053622, Training Accuracy= 0.48438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 592/782 [00:42<00:16, 11.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 590.0, Minibatch Loss= 1.059896, Training Accuracy= 0.43750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 604/782 [00:43<00:12, 13.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 600.0, Minibatch Loss= 1.034869, Training Accuracy= 0.49219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 612/782 [00:44<00:16, 10.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 610.0, Minibatch Loss= 1.040174, Training Accuracy= 0.53125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 622/782 [00:45<00:21,  7.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 620.0, Minibatch Loss= 0.999681, Training Accuracy= 0.54688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 632/782 [00:46<00:12, 11.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 630.0, Minibatch Loss= 1.034889, Training Accuracy= 0.46875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 644/782 [00:47<00:09, 14.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 640.0, Minibatch Loss= 1.028382, Training Accuracy= 0.50781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 652/782 [00:48<00:16,  7.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 650.0, Minibatch Loss= 1.011249, Training Accuracy= 0.49219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 662/782 [00:49<00:11, 10.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 660.0, Minibatch Loss= 1.018264, Training Accuracy= 0.51562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 672/782 [00:50<00:08, 12.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 670.0, Minibatch Loss= 1.026383, Training Accuracy= 0.47656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 682/782 [00:51<00:10,  9.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 680.0, Minibatch Loss= 1.045176, Training Accuracy= 0.48438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 694/782 [00:52<00:07, 12.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 690.0, Minibatch Loss= 1.036672, Training Accuracy= 0.46875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 704/782 [00:52<00:05, 13.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 700.0, Minibatch Loss= 1.049109, Training Accuracy= 0.44531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 712/782 [00:53<00:07,  9.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 710.0, Minibatch Loss= 1.071600, Training Accuracy= 0.46875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 723/782 [00:55<00:07,  8.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 720.0, Minibatch Loss= 1.020035, Training Accuracy= 0.47656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 733/782 [00:56<00:04, 10.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 730.0, Minibatch Loss= 1.040412, Training Accuracy= 0.48438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 742/782 [00:57<00:05,  7.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 740.0, Minibatch Loss= 0.994069, Training Accuracy= 0.51562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 752/782 [00:58<00:04,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 750.0, Minibatch Loss= 1.014977, Training Accuracy= 0.54688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 763/782 [00:59<00:02,  9.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 760.0, Minibatch Loss= 1.020595, Training Accuracy= 0.53125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 772/782 [01:00<00:00, 10.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 770.0, Minibatch Loss= 0.975701, Training Accuracy= 0.55469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [01:01<00:00, 12.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 780.0, Minibatch Loss= 1.003754, Training Accuracy= 0.55469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Use TQDM if installed\n",
    "tqdm_installed = False\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "    tqdm_installed = True\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Launch the Tensorflow session\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# training_iterations_count: The number of data pieces to train on in total\n",
    "# batch_size: The number of data pieces per batch\n",
    "training_iterations = range(0,training_iterations_count,batch_size)\n",
    "if tqdm_installed:\n",
    "    # Add a progress bar if TQDM is installed\n",
    "    training_iterations = tqdm(training_iterations)\n",
    "\n",
    "for i in training_iterations:\n",
    "\n",
    "    # Select indices for a random data subset\n",
    "    batch = np.random.randint(data_feature_list[0].shape[0], size=batch_size)\n",
    "    \n",
    "    # Use the selected subset indices to initialize the graph's \n",
    "    #   placeholder values\n",
    "    hyps, evis, ys = (data_feature_list[0][batch,:],\n",
    "                      data_feature_list[1][batch,:],\n",
    "                      correct_scores[batch])\n",
    "    \n",
    "    # Run the optimization with these initialized values\n",
    "    sess.run([opt_op], feed_dict={hyp: hyps, evi: evis, y: ys})\n",
    "    # display_step: how often the accuracy and loss should \n",
    "    #   be tested and displayed.\n",
    "    if (i/batch_size) % display_step == 0:\n",
    "        # Calculate batch accuracy\n",
    "        acc = sess.run(accuracy, feed_dict={hyp: hyps, evi: evis, y: ys})\n",
    "        # Calculate batch loss\n",
    "        tmp_loss = sess.run(loss, feed_dict={hyp: hyps, evi: evis, y: ys})\n",
    "        # Display results\n",
    "        print(\"Iter \" + str(i/batch_size) + \", Minibatch Loss= \" + \\\n",
    "              \"{:.6f}\".format(tmp_loss) + \", Training Accuracy= \" + \\\n",
    "              \"{:.5f}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive entailment\n"
     ]
    }
   ],
   "source": [
    "evidences = [\"Maurita and Jade both were at the scene of the car crash.\"]\n",
    "\n",
    "hypotheses = [\"Multiple people saw the accident.\"]\n",
    "\n",
    "sentence1 = [fit_to_size(np.vstack(sentence2sequence(evidence)[0]),\n",
    "                         (30, 50)) for evidence in evidences]\n",
    "\n",
    "sentence2 = [fit_to_size(np.vstack(sentence2sequence(hypothesis)[0]),\n",
    "                         (30,50)) for hypothesis in hypotheses]\n",
    "\n",
    "prediction = sess.run(classification_scores, feed_dict={hyp: (sentence1 * N),\n",
    "                                                        evi: (sentence2 * N),\n",
    "                                                        y: [[0,0,0]]*N})\n",
    "print([\"Positive\", \"Neutral\", \"Negative\"][np.argmax(prediction[0])]+\n",
    "      \" entailment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
